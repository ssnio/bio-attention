{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # header\n",
    "import sys\n",
    "sys.path.append(r\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # built-in modules\n",
    "import os\n",
    "from pprint import pformat\n",
    "from collections import OrderedDict\n",
    "# # Torch modules\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms, datasets\n",
    "# # internal imports\n",
    "from prelude import startup_folders, get_device, load_dicts\n",
    "from src.composer import IOR_DS, Arrow_DS, Cue_DS, Recognition_DS\n",
    "from src.composer import Search_DS, Tracking_DS, Popout_DS\n",
    "from src.model import AttentionModel\n",
    "from src.utils import plot_all\n",
    "from src.utils import build_loaders\n",
    "from src.conductor import AttentionTrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pretrained/mnist_v2/1753528396 was created!\n"
     ]
    }
   ],
   "source": [
    "start_folder = r\"../pretrained/mnist_v2\"\n",
    "results_folder, logger = startup_folders(start_folder, name=f\"exp_mnist\")\n",
    "data_path = r\"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to mps\n",
      "model_params: {'in_dims': [3, 96, 96], 'n_classes': 10, 'out_dim': 20, 'normalize': True, 'softness': 0.5, 'channels': [3, 16, 32, 64, 128, 128], 'residuals': False, 'kernels': 3, 'strides': 1, 'paddings': 1, 'conv_bias': True, 'conv_norms': [None, 'layer', 'layer', 'layer', 'layer'], 'conv_dropouts': 0.0, 'conv_funs': ReLU(), 'deconv_funs': Tanh(), 'deconv_norms': [None, 'layer', 'layer', 'layer', 'layer'], 'pools': [2, 2, 2, 2, 3], 'rnn_dims': [128, 64], 'rnn_bias': True, 'rnn_dropouts': 0.0, 'rnn_funs': ReLU(), 'n_tasks': 7, 'task_layers': 1, 'task_weight': True, 'task_bias': True, 'task_funs': Tanh(), 'norm_mean': [0.5, 0.5, 0.5], 'norm_std': [1.0, 1.0, 1.0], 'rnn_to_fc': False, 'trans_fun': ReLU()}\n",
      "tasks: {'IOR': {'composer': 'IOR_DS', 'key': 0, 'params': {'n_digits': 3, 'n_attend': 2, 'noise': 0.25, 'overlap': 1.0}, 'datasets': ['IOR_DS', 'IOR_DS', 'IOR_DS'], 'dataloaders': [None, None, None], 'loss_w': [1.0, 1.0, 0.0], 'loss_s': [None, None], 'has_prompt': False}, 'Arrow': {'composer': 'Arrow_DS', 'key': 1, 'params': {'n_iter': 3, 'noise': 0.25, 'directory': './data'}, 'datasets': ['Arrow_DS', 'Arrow_DS', 'Arrow_DS'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 0.0, 1.0], 'loss_s': [None, None], 'has_prompt': False}, 'Cue': {'composer': 'Cue_DS', 'key': 2, 'params': {'fix_attend': [2, 3], 'n_digits': 4, 'noise': 0.25, 'overlap': 0.0}, 'datasets': ['Cue_DS', 'Cue_DS', 'Cue_DS'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 1.0, 1.0], 'loss_s': '((4,), slice(1, None, None))', 'has_prompt': False}, 'Tracking': {'composer': 'Tracking_DS', 'key': 3, 'params': {'fix_attend': [2, 5], 'n_digits': 4, 'noise': 0.25}, 'datasets': ['Tracking_DS', 'Tracking_DS', 'Tracking_DS'], 'dataloaders': [None, None, None], 'loss_w': [1.0, 1.0, 1.0], 'loss_s': '(slice(1, None, None), slice(1, None, None))', 'has_prompt': False}, 'Recognition': {'composer': 'Recognition_DS', 'key': 4, 'params': {'n_iter': 3, 'stride': 16, 'blank': False, 'static': False, 'noise': 0.25}, 'datasets': ['Recognition_DS', 'Recognition_DS', 'Recognition_DS'], 'dataloaders': [None, None, None], 'loss_w': [1.0, 0.0, 2.0], 'loss_s': '(slice(1, None, None), None)', 'has_prompt': False}, 'Search': {'composer': 'Search_DS', 'key': 5, 'params': {'n_iter': 2, 'n_digits': 4, 'noise': 0.25, 'overlap': 1.0}, 'datasets': ['Search_DS', 'Search_DS', 'Search_DS'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 1.0, 0.0], 'loss_s': '(None, slice(1, None, None))', 'has_prompt': True}, 'Popout': {'composer': 'Popout_DS', 'key': 6, 'params': {'n_iter': 2, 'noise': 0.25}, 'datasets': ['Popout_DS', 'Popout_DS', 'Popout_DS'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 0.0, 1.0], 'loss_s': [None, None], 'has_prompt': False}}\n",
      "train_params: {'n_epochs': 96, 'batch_size': 128, 'lr': 0.0005, 'l2': 1e-06, 'exase': 'default', 'dir': './results', 'milestones': [32, 64], 'gamma': 0.2, 'max_grad_norm': 10.0}\n"
     ]
    }
   ],
   "source": [
    "model_params = load_dicts(start_folder, \"model_params\")\n",
    "tasks = load_dicts(start_folder, \"tasks\")\n",
    "train_params = load_dicts(start_folder, \"train_params\")\n",
    "DeVice, num_workers, pin_memory = get_device()\n",
    "print(f\"model_params: {model_params}\")\n",
    "print(f\"tasks: {tasks}\")\n",
    "print(f\"train_params: {train_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setting up the tasks\n",
    "tasks['IOR'][\"composer\"] = IOR_DS\n",
    "tasks['Arrow'][\"composer\"] = Arrow_DS\n",
    "tasks['Cue'][\"composer\"] = Cue_DS\n",
    "tasks['Tracking'][\"composer\"] = Tracking_DS\n",
    "tasks['Recognition'][\"composer\"] = Recognition_DS\n",
    "tasks['Search'][\"composer\"] = Search_DS\n",
    "tasks['Popout'][\"composer\"] = Popout_DS\n",
    "\n",
    "tasks['IOR'][\"datasets\"] = []\n",
    "tasks['Arrow'][\"datasets\"] = []\n",
    "tasks['Cue'][\"datasets\"] = []\n",
    "tasks['Tracking'][\"datasets\"] = []\n",
    "tasks['Recognition'][\"datasets\"] = []\n",
    "tasks['Search'][\"datasets\"] = []\n",
    "tasks['Popout'][\"datasets\"] = []\n",
    "\n",
    "tasks['IOR'][\"dataloaders\"] = []\n",
    "tasks['Arrow'][\"dataloaders\"] = []\n",
    "tasks['Cue'][\"dataloaders\"] = []\n",
    "tasks['Tracking'][\"dataloaders\"] = []\n",
    "tasks['Recognition'][\"dataloaders\"] = []\n",
    "tasks['Search'][\"dataloaders\"] = []\n",
    "tasks['Popout'][\"dataloaders\"] = []\n",
    "\n",
    "tasks['IOR'][\"loss_s\"] =  ((-1, ), (-1, ))\n",
    "tasks['Arrow'][\"loss_s\"] =  ((-1, ), (-1, ))\n",
    "tasks['Cue'][\"loss_s\"] =  ((-1, ), (-1, ))\n",
    "tasks['Tracking'][\"loss_s\"] =  ((-1, ), (-1, ))\n",
    "tasks['Recognition'][\"loss_s\"] = ((-1, ), (-1, ))\n",
    "tasks['Search'][\"loss_s\"] =  ((-1, ), (-1, ))\n",
    "tasks['Popout'][\"loss_s\"] =  ((-1, ), (-1, ))\n",
    "\n",
    "tasks['Arrow'][\"params\"][\"directory\"] = data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to mps\n"
     ]
    }
   ],
   "source": [
    "# datasets and dataloaders\n",
    "tralid_ds = datasets.MNIST(root=data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "test_ds = datasets.MNIST(root=data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "train_ds, valid_ds = random_split(tralid_ds, (50000, 10000))\n",
    "DeVice, num_workers, pin_memory = get_device()\n",
    "for o in tasks:\n",
    "    tasks[o][\"datasets\"].append(tasks[o][\"composer\"](train_ds, **tasks[o][\"params\"]))\n",
    "    tasks[o][\"datasets\"].append(tasks[o][\"composer\"](valid_ds, **tasks[o][\"params\"]))\n",
    "    tasks[o][\"datasets\"].append(tasks[o][\"composer\"](test_ds, **tasks[o][\"params\"]))\n",
    "    tasks[o][\"datasets\"][1].build_valid_test()\n",
    "    tasks[o][\"datasets\"][2].build_valid_test()\n",
    "    tasks[o][\"dataloaders\"] = build_loaders(tasks[o][\"datasets\"], batch_size=train_params[\"batch_size\"], num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a blank model\n",
    "model = AttentionModel(**model_params)\n",
    "conductor = AttentionTrain(model, None, None, tasks, logger, results_folder)\n",
    "\n",
    "# load states into the model\n",
    "model_dir = os.path.join(start_folder, \"model\" + \".pth\")\n",
    "assert os.path.exists(model_dir), \"Could not find the model.pth in the given dir!\"\n",
    "model.load_state_dict(torch.load(model_dir, map_location=DeVice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting...\n",
    "plot_all(10, model, tasks, results_folder, \"_test\", DeVice, logger, False, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing...\n",
      "  Task IOR:\n",
      "    CEi Loss: 0.133    CEe Loss: 0.000    Pix Err: 0.004    Att Acc: 0.831    Cls Acc: 9536/10000\n",
      "  Task Arrow:\n",
      "    CEi Loss: 1.192    CEe Loss: 0.023    Pix Err: 0.021    Att Acc: 0.926    Cls Acc: 9927/10000\n",
      "  Task Cue:\n",
      "    CEi Loss: 0.101    CEe Loss: 0.038    Pix Err: 0.002    Att Acc: 0.870    Cls Acc: 9877/10000\n",
      "  Task Tracking:\n",
      "    CEi Loss: 0.023    CEe Loss: 0.024    Pix Err: 0.009    Att Acc: 0.741    Cls Acc: 9945/10000\n",
      "  Task Recognition:\n",
      "    CEi Loss: 0.031    CEe Loss: 0.032    Pix Err: 0.009    Att Acc: 0.941    Cls Acc: 9908/10000\n",
      "  Task Search:\n",
      "    CEi Loss: 1.660    CEe Loss: 0.563    Pix Err: 0.002    Att Acc: 0.830    Cls Acc: 8967/10000\n",
      "  Task Popout:\n",
      "    CEi Loss: 0.634    CEe Loss: 0.028    Pix Err: 0.019    Att Acc: 0.911    Cls Acc: 9912/10000\n"
     ]
    }
   ],
   "source": [
    "# evaluating...\n",
    "conductor.eval(DeVice, \"test\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
