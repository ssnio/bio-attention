{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # header\n",
    "import sys\n",
    "sys.path.append(r\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # built-in modules\n",
    "import os\n",
    "from pprint import pformat\n",
    "from collections import OrderedDict\n",
    "# # Torch modules\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms, datasets\n",
    "# # internal imports\n",
    "from prelude import startup_folders, get_device, load_dicts\n",
    "from src.composer import Recognition_DS, PatternedRecognition_DS\n",
    "from src.model import AttentionModel\n",
    "from src.utils import plot_all\n",
    "from src.utils import build_loaders\n",
    "from src.conductor import AttentionTrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pretrained/mnist_v2/1753527155 was created!\n"
     ]
    }
   ],
   "source": [
    "start_folder = r\"../pretrained/mnist_v2\"\n",
    "results_folder, logger = startup_folders(start_folder, name=f\"exp_a\")\n",
    "data_path = r\"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to mps\n",
      "model_params: {'in_dims': [3, 96, 96], 'n_classes': 10, 'out_dim': 20, 'normalize': True, 'softness': 0.5, 'channels': [3, 16, 32, 64, 128, 128], 'residuals': False, 'kernels': 3, 'strides': 1, 'paddings': 1, 'conv_bias': True, 'conv_norms': [None, 'layer', 'layer', 'layer', 'layer'], 'conv_dropouts': 0.0, 'conv_funs': ReLU(), 'deconv_funs': Tanh(), 'deconv_norms': [None, 'layer', 'layer', 'layer', 'layer'], 'pools': [2, 2, 2, 2, 3], 'rnn_dims': [128, 64], 'rnn_bias': True, 'rnn_dropouts': 0.0, 'rnn_funs': ReLU(), 'n_tasks': 7, 'task_layers': 1, 'task_weight': True, 'task_bias': True, 'task_funs': Tanh(), 'norm_mean': [0.5, 0.5, 0.5], 'norm_std': [1.0, 1.0, 1.0], 'rnn_to_fc': False, 'trans_fun': ReLU()}\n",
      "tasks: {'IOR': {'composer': 'IOR_DS', 'key': 0, 'params': {'n_digits': 3, 'n_attend': 2, 'noise': 0.25, 'overlap': 1.0}, 'datasets': ['IOR_DS', 'IOR_DS', 'IOR_DS'], 'dataloaders': [None, None, None], 'loss_w': [1.0, 1.0, 0.0], 'loss_s': [None, None], 'has_prompt': False}, 'Arrow': {'composer': 'Arrow_DS', 'key': 1, 'params': {'n_iter': 3, 'noise': 0.25, 'directory': './data'}, 'datasets': ['Arrow_DS', 'Arrow_DS', 'Arrow_DS'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 0.0, 1.0], 'loss_s': [None, None], 'has_prompt': False}, 'Cue': {'composer': 'Cue_DS', 'key': 2, 'params': {'fix_attend': [2, 3], 'n_digits': 4, 'noise': 0.25, 'overlap': 0.0}, 'datasets': ['Cue_DS', 'Cue_DS', 'Cue_DS'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 1.0, 1.0], 'loss_s': '((4,), slice(1, None, None))', 'has_prompt': False}, 'Tracking': {'composer': 'Tracking_DS', 'key': 3, 'params': {'fix_attend': [2, 5], 'n_digits': 4, 'noise': 0.25}, 'datasets': ['Tracking_DS', 'Tracking_DS', 'Tracking_DS'], 'dataloaders': [None, None, None], 'loss_w': [1.0, 1.0, 1.0], 'loss_s': '(slice(1, None, None), slice(1, None, None))', 'has_prompt': False}, 'Recognition': {'composer': 'Recognition_DS', 'key': 4, 'params': {'n_iter': 3, 'stride': 16, 'blank': False, 'static': False, 'noise': 0.25}, 'datasets': ['Recognition_DS', 'Recognition_DS', 'Recognition_DS'], 'dataloaders': [None, None, None], 'loss_w': [1.0, 0.0, 2.0], 'loss_s': '(slice(1, None, None), None)', 'has_prompt': False}, 'Search': {'composer': 'Search_DS', 'key': 5, 'params': {'n_iter': 2, 'n_digits': 4, 'noise': 0.25, 'overlap': 1.0}, 'datasets': ['Search_DS', 'Search_DS', 'Search_DS'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 1.0, 0.0], 'loss_s': '(None, slice(1, None, None))', 'has_prompt': True}, 'Popout': {'composer': 'Popout_DS', 'key': 6, 'params': {'n_iter': 2, 'noise': 0.25}, 'datasets': ['Popout_DS', 'Popout_DS', 'Popout_DS'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 0.0, 1.0], 'loss_s': [None, None], 'has_prompt': False}}\n",
      "train_params: {'n_epochs': 96, 'batch_size': 128, 'lr': 0.0005, 'l2': 1e-06, 'exase': 'default', 'dir': './results', 'milestones': [32, 64], 'gamma': 0.2, 'max_grad_norm': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'composer': 'Recognition_DS',\n",
       " 'key': 4,\n",
       " 'params': {'n_iter': 3,\n",
       "  'stride': 16,\n",
       "  'blank': False,\n",
       "  'static': False,\n",
       "  'noise': 0.25},\n",
       " 'datasets': ['Recognition_DS', 'Recognition_DS', 'Recognition_DS'],\n",
       " 'dataloaders': [None, None, None],\n",
       " 'loss_w': [1.0, 0.0, 2.0],\n",
       " 'loss_s': '(slice(1, None, None), None)',\n",
       " 'has_prompt': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = load_dicts(start_folder, \"model_params\")\n",
    "tasks = load_dicts(start_folder, \"tasks\")\n",
    "train_params = load_dicts(start_folder, \"train_params\")\n",
    "DeVice, num_workers, pin_memory = get_device()\n",
    "print(f\"model_params: {model_params}\")\n",
    "print(f\"tasks: {tasks}\")\n",
    "print(f\"train_params: {train_params}\")\n",
    "tasks['Recognition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = OrderedDict({})\n",
    "\n",
    "tasks[\"Rec_VisDyn\"] = {\n",
    "    \"composer\": Recognition_DS,\n",
    "    \"key\": 4,\n",
    "    \"params\": {\"n_iter\": 3, \"stride\": 16, \"blank\": False, \"static\": False, \"noise\": 0.25},\n",
    "    \"datasets\": [],\n",
    "    \"dataloaders\": [],\n",
    "    \"loss_w\": (1.0, 0.0, 2.0),  # labels, masks, last label\n",
    "    \"loss_s\": (slice(1, None), None),  # labels, masks\n",
    "    \"has_prompt\": False,\n",
    "}\n",
    "tasks[\"Rec_VisStat\"] = {\n",
    "    \"composer\": Recognition_DS,\n",
    "    \"key\": 4,\n",
    "    \"params\": {\"n_iter\": 3, \"stride\": 16, \"blank\": False, \"static\": True, \"noise\": 0.25},\n",
    "    \"datasets\": [],\n",
    "    \"dataloaders\": [],\n",
    "    \"loss_w\": (1.0, 0.0, 2.0),  # labels, masks, last label\n",
    "    \"loss_s\": (slice(1, None), None),  # labels, masks\n",
    "    \"has_prompt\": False,\n",
    "}\n",
    "tasks[\"Rec_inVisDyn\"] = {\n",
    "    \"composer\": Recognition_DS,\n",
    "    \"key\": 4,\n",
    "    \"params\": {\"n_iter\": 3, \"stride\": 16, \"blank\": True, \"static\": False, \"noise\": 0.25},\n",
    "    \"datasets\": [],\n",
    "    \"dataloaders\": [],\n",
    "    \"loss_w\": (1.0, 0.0, 2.0),  # labels, masks, last label\n",
    "    \"loss_s\": (slice(1, None), None),  # labels, masks\n",
    "    \"has_prompt\": False,\n",
    "}\n",
    "tasks[\"Rec_inVisStat\"] = {\n",
    "    \"composer\": Recognition_DS,\n",
    "    \"key\": 4,\n",
    "    \"params\": {\"n_iter\": 3, \"stride\": 16, \"blank\": True, \"static\": True, \"noise\": 0.25},\n",
    "    \"datasets\": [],\n",
    "    \"dataloaders\": [],\n",
    "    \"loss_w\": (1.0, 0.0, 2.0),  # labels, masks, last label\n",
    "    \"loss_s\": (slice(1, None), None),  # labels, masks\n",
    "    \"has_prompt\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks[\"PatternedRecognition\"] = {\n",
    "    \"composer\": PatternedRecognition_DS,\n",
    "    \"key\": 4,\n",
    "    \"params\": {\"n_iter\": 3, \"noise\": 0.25},\n",
    "    \"datasets\": [],\n",
    "    \"dataloaders\": [],\n",
    "    \"loss_w\": (0.0, 0.0, 0.0),  # labels, masks, last label\n",
    "    \"loss_s\": (None, None),  # labels, masks\n",
    "    \"has_prompt\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to mps\n"
     ]
    }
   ],
   "source": [
    "# datasets and dataloaders\n",
    "tralid_ds = datasets.MNIST(root=data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "test_ds = datasets.MNIST(root=data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "train_ds, valid_ds = random_split(tralid_ds, (50000, 10000))\n",
    "DeVice, num_workers, pin_memory = get_device()\n",
    "for o in tasks:\n",
    "    tasks[o][\"datasets\"].append(tasks[o][\"composer\"](train_ds, **tasks[o][\"params\"]))\n",
    "    tasks[o][\"datasets\"].append(tasks[o][\"composer\"](valid_ds, **tasks[o][\"params\"]))\n",
    "    tasks[o][\"datasets\"].append(tasks[o][\"composer\"](test_ds, **tasks[o][\"params\"]))\n",
    "    tasks[o][\"datasets\"][1].build_valid_test()\n",
    "    tasks[o][\"datasets\"][2].build_valid_test()\n",
    "    tasks[o][\"dataloaders\"] = build_loaders(tasks[o][\"datasets\"], batch_size=train_params[\"batch_size\"], num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a blank model\n",
    "model = AttentionModel(**model_params)\n",
    "conductor = AttentionTrain(model, None, None, tasks, logger, results_folder)\n",
    "\n",
    "# load states into the model\n",
    "model_dir = os.path.join(start_folder, \"model\" + \".pth\")\n",
    "assert os.path.exists(model_dir), \"Could not find the model.pth in the given dir!\"\n",
    "model.load_state_dict(torch.load(model_dir, map_location=DeVice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing...\n",
      "  Task Rec_VisDyn:\n",
      "    CEi Loss: 0.075    CEe Loss: 0.032    Pix Err: 0.013    Att Acc: 0.853    Cls Acc: 9910/10000\n",
      "  Task Rec_VisStat:\n",
      "    CEi Loss: 0.182    CEe Loss: 0.095    Pix Err: 0.014    Att Acc: 0.856    Cls Acc: 9691/10000\n",
      "  Task Rec_inVisDyn:\n",
      "    CEi Loss: 0.400    CEe Loss: 0.159    Pix Err: 0.015    Att Acc: 0.788    Cls Acc: 9517/10000\n",
      "  Task Rec_inVisStat:\n",
      "    CEi Loss: 1.157    CEe Loss: 0.642    Pix Err: 0.015    Att Acc: 0.779    Cls Acc: 8400/10000\n",
      "  Task PatternedRecognition:\n",
      "    CEi Loss: 2.365    CEe Loss: 0.084    Pix Err: 0.014    Att Acc: 0.829    Cls Acc: 9716/10000\n"
     ]
    }
   ],
   "source": [
    "# evaluating...\n",
    "conductor.eval(DeVice, \"test\", False)\n",
    "# plotting...\n",
    "plot_all(10, model, tasks, results_folder, \"_test\", DeVice, logger, False, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing...\n",
      "  Task Rec_VisDyn:\n",
      "    CEi Loss: 2.150    Pix Err: 0.021    Att Acc: 0.926    Cls Acc: 2786/10000\n",
      "    CEi Loss: 0.047    Pix Err: 0.010    Att Acc: 0.692    Cls Acc: 9862/10000\n",
      "    CEi Loss: 0.035    Pix Err: 0.009    Att Acc: 0.941    Cls Acc: 9899/10000\n",
      "    CEi Loss: 0.036    Pix Err: 0.009    Att Acc: 0.769    Cls Acc: 9900/10000\n",
      "  Task Rec_VisStat:\n",
      "    CEi Loss: 2.147    Pix Err: 0.021    Att Acc: 0.926    Cls Acc: 2844/10000\n",
      "    CEi Loss: 0.086    Pix Err: 0.010    Att Acc: 0.698    Cls Acc: 9725/10000\n",
      "    CEi Loss: 0.091    Pix Err: 0.010    Att Acc: 0.948    Cls Acc: 9721/10000\n",
      "    CEi Loss: 0.092    Pix Err: 0.010    Att Acc: 0.753    Cls Acc: 9725/10000\n",
      "  Task Rec_inVisDyn:\n",
      "    CEi Loss: 1.853    Pix Err: 0.024    Att Acc: 0.841    Cls Acc: 5062/10000\n",
      "    CEi Loss: 0.263    Pix Err: 0.011    Att Acc: 0.632    Cls Acc: 9186/10000\n",
      "    CEi Loss: 0.169    Pix Err: 0.009    Att Acc: 0.890    Cls Acc: 9500/10000\n",
      "    CEi Loss: 0.173    Pix Err: 0.011    Att Acc: 0.671    Cls Acc: 9492/10000\n",
      "  Task Rec_inVisStat:\n",
      "    CEi Loss: 1.849    Pix Err: 0.024    Att Acc: 0.841    Cls Acc: 5108/10000\n",
      "    CEi Loss: 0.576    Pix Err: 0.012    Att Acc: 0.602    Cls Acc: 8346/10000\n",
      "    CEi Loss: 0.648    Pix Err: 0.009    Att Acc: 0.896    Cls Acc: 8345/10000\n",
      "    CEi Loss: 0.677    Pix Err: 0.011    Att Acc: 0.649    Cls Acc: 8301/10000\n",
      "  Task PatternedRecognition:\n",
      "    CEi Loss: 2.204    Pix Err: 0.022    Att Acc: 0.925    Cls Acc: 2749/10000\n",
      "    CEi Loss: 0.086    Pix Err: 0.013    Att Acc: 0.627    Cls Acc: 9697/10000\n",
      "    CEi Loss: 0.091    Pix Err: 0.009    Att Acc: 0.934    Cls Acc: 9701/10000\n",
      "    CEi Loss: 0.095    Pix Err: 0.012    Att Acc: 0.678    Cls Acc: 9688/10000\n"
     ]
    }
   ],
   "source": [
    "# evaluating sequence one iteration at a time\n",
    "conductor.eval_seq(DeVice, \"test\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
