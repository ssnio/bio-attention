{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # header\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imports\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "from pprint import pformat\n",
    "from collections import OrderedDict\n",
    "from src.composer import COCOTokens, COCOAnimals, BG20k\n",
    "from src.composer import PerceptualGrouping_COCO, Recognition_COCO, Search_COCO, SearchGrid_COCO\n",
    "from src.conductor import AttentionTrain\n",
    "from src.modelv2 import AttentionModel\n",
    "from src.utils import plot_all, plot_loss_all\n",
    "from src.utils import build_loaders, get_n_parameters\n",
    "from prelude import get_device, startup_folders, load_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_folder = r\"../pretrained/coco_v2\"\n",
    "results_folder, logger = startup_folders(start_folder, name=f\"exp_coco\")\n",
    "data_path = r\"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = load_dicts(start_folder, \"model_params\")\n",
    "tasks = load_dicts(start_folder, \"tasks\")\n",
    "train_params = load_dicts(start_folder, \"train_params\")\n",
    "DeVice, num_workers, pin_memory = get_device()\n",
    "print(f\"model_params: {model_params}\")\n",
    "print(f\"tasks: {tasks}\")\n",
    "print(f\"train_params: {train_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks['Recognition'][\"composer\"] = Recognition_COCO\n",
    "tasks['PerceptualGrouping'][\"composer\"] = PerceptualGrouping_COCO\n",
    "tasks['Search'][\"composer\"] = Search_COCO\n",
    "tasks['SearchGrid'][\"composer\"] = SearchGrid_COCO\n",
    "\n",
    "tasks['Recognition'][\"datasets\"] = []\n",
    "tasks['PerceptualGrouping'][\"datasets\"] = []\n",
    "tasks['Search'][\"datasets\"] = []\n",
    "tasks['SearchGrid'][\"datasets\"] = []\n",
    "\n",
    "tasks['Recognition'][\"dataloaders\"] = []\n",
    "tasks['PerceptualGrouping'][\"dataloaders\"] = []\n",
    "tasks['Search'][\"dataloaders\"] = []\n",
    "tasks['SearchGrid'][\"dataloaders\"] = []\n",
    "\n",
    "tasks['Recognition'][\"loss_s\"] = (slice(0, None, None), slice(0, None, None))\n",
    "tasks['PerceptualGrouping'][\"loss_s\"] = (slice(1, None, None), slice(1, None, None))\n",
    "tasks['Search'][\"loss_s\"] = (slice(1, None, None), slice(1, None, None))\n",
    "tasks['SearchGrid'][\"loss_s\"] = (slice(1, None, None), slice(1, None, None))\n",
    "\n",
    "tasks['Recognition'][\"loss_s\"] = ((-1, ), (-1, ))\n",
    "tasks['PerceptualGrouping'][\"loss_s\"] = ((-1, ), (-1, ))\n",
    "tasks['Search'][\"loss_s\"] = ((-1, ), (-1, ))\n",
    "tasks['SearchGrid'][\"loss_s\"] = ((-1, ), (-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets and dataloaders\n",
    "coco_tokens = COCOTokens(directory=data_path, animals=True, split=0.9)\n",
    "train_tks, valid_tks, test_tks = coco_tokens.get_tokens()\n",
    "train_coco = COCOAnimals(in_dims=model_params[\"in_dims\"], directory=data_path, kind=0, tokens=train_tks)\n",
    "valid_coco = COCOAnimals(in_dims=model_params[\"in_dims\"], directory=data_path, kind=1, tokens=valid_tks)\n",
    "test_coco = COCOAnimals(in_dims=model_params[\"in_dims\"], directory=data_path, kind=2, tokens=test_tks)\n",
    "train_bg = BG20k(root=data_path, kind=\"train\")\n",
    "test_bg = valid_bg = BG20k(root=data_path, kind=\"test\")\n",
    "DeVice, num_workers, pin_memory = get_device()\n",
    "for o in tasks:\n",
    "    if tasks[o][\"composer\"] in (Recognition_COCO , SearchGrid_COCO):\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](train_coco, **tasks[o][\"params\"], bg_dataset=train_bg))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](valid_coco, **tasks[o][\"params\"], bg_dataset=valid_bg))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](test_coco, **tasks[o][\"params\"], bg_dataset=test_bg))\n",
    "    else:\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](train_coco, **tasks[o][\"params\"]))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](valid_coco, **tasks[o][\"params\"]))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](test_coco, **tasks[o][\"params\"]))\n",
    "    tasks[o][\"datasets\"][1].build_valid_test()\n",
    "    tasks[o][\"datasets\"][2].build_valid_test()\n",
    "    tasks[o][\"dataloaders\"] = build_loaders(tasks[o][\"datasets\"], batch_size=train_params[\"batch_size\"], num_workers=num_workers, pin_memory=pin_memory, shuffle=False)\n",
    "assert model_params[\"n_classes\"] == train_coco.n_classes, f\"Number of n_classes {model_params['n_classes']} and n_classes {train_coco.n_classes} must be equal!\"\n",
    "tasks[\"PerceptualGrouping\"][\"class_weights\"] = train_coco.class_weights if hasattr(train_coco, \"class_weights\") else None\n",
    "tasks[\"Recognition\"][\"class_weights\"] = train_coco.class_weights if hasattr(train_coco, \"class_weights\") else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and optimizer...\n",
    "model = AttentionModel(**model_params)\n",
    "model_trainer = AttentionTrain(model, None, None, tasks, logger, results_folder)\n",
    "model_dir = os.path.join(start_folder, \"model\" + \".pth\")\n",
    "assert os.path.exists(model_dir), \"Could not find the model.pth in the given dir!\"\n",
    "model.load_state_dict(torch.load(model_dir, map_location=DeVice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "plot_all(10, model, tasks, results_folder, \"_test\", DeVice, logger, False, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating...\n",
    "model_trainer.eval(DeVice, \"test\", False)\n",
    "model_trainer.eval(DeVice, \"valid\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in model.modules():\n",
    "    if isinstance(a, torch.nn.BatchNorm2d):\n",
    "        print(a)\n",
    "        print(a.running_mean.mean() if a.running_mean is not None else None, a.running_var.mean() if a.running_var is not None else None)\n",
    "        if a.running_mean is None or a.running_var is None:\n",
    "            a.running_mean, a.running_var = torch.zeros(a.num_features).to(DeVice), torch.ones(a.num_features).to(DeVice)\n",
    "        a.train()\n",
    "        a.track_running_stats = True\n",
    "        a.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.bmv = {}\n",
    "# model.bmv_stuff = []\n",
    "# model.bmv_i = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.track_stats(DeVice, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bmv_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model.bmv.items():\n",
    "    print(k)\n",
    "    print(v[0].mean(), v[1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in model.modules():\n",
    "    if isinstance(a, torch.nn.BatchNorm2d):\n",
    "        print(a)\n",
    "        print(a.running_mean.mean(), a.running_var.mean())\n",
    "        # if a.running_mean is None or a.running_var is None:\n",
    "        #     a.running_mean, a.running_var = torch.zeros(a.num_features).to(device), torch.ones(a.num_features).to(device)\n",
    "        # a.train()\n",
    "        # a.track_running_stats = True\n",
    "        # a.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating...\n",
    "model_trainer.eval(DeVice, \"test\", False)\n",
    "model_trainer.eval(DeVice, \"valid\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1297/1558"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.track_stats(DeVice, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating...\n",
    "model_trainer.eval(DeVice, \"test\", False)\n",
    "model_trainer.eval(DeVice, \"valid\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.track_stats(DeVice, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating...\n",
    "model_trainer.stop_tracking()\n",
    "model_trainer.eval(DeVice, \"test\", False)\n",
    "model_trainer.eval(DeVice, \"valid\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox\n",
    "from src.resnet_ import ResNet\n",
    "import time\n",
    "\n",
    "class SimpModel(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 n: int\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, x: torch.Tensor):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        self.model.eval()\n",
    "        if x.ndim == 4:\n",
    "            x = x.unsqueeze(1)\n",
    "        elif x.ndim == 5:\n",
    "            assert x.size(1) == 1\n",
    "        x = x.repeat(1, self.n, 1, 1, 1)\n",
    "        _ = self.model.forward(x, 0)\n",
    "        y, _ = self.model.for_forward(x[:, -1])\n",
    "        return y\n",
    "\n",
    "\n",
    "def adv_robustness(model_, dataloader_, device_, kind, epsilons_, preprocessing_ = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)):\n",
    "    bounds = bounds = (0, 1)\n",
    "    n = dataloader_.dataset.n_iter\n",
    "    model = model_ if isinstance(model_, ResNet) else SimpModel(model_, n)\n",
    "    model.to(device_)\n",
    "    model.eval()\n",
    "    fmodel = foolbox.PyTorchModel(model, bounds=bounds, device=device_, preprocessing=preprocessing_)\n",
    "    if kind == \"Linf\":\n",
    "        attack = foolbox.attacks.LinfDeepFoolAttack(steps=100, loss='crossentropy')\n",
    "    elif kind == \"L2\":\n",
    "        attack = foolbox.attacks.L2DeepFoolAttack(steps=100, loss='crossentropy')\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown kind of attack: {kind}\")\n",
    "    pre_acc = 0.0\n",
    "    n_samples = 0\n",
    "    epsilons_ = epsilons_.to(device_) if isinstance(epsilons_, torch.Tensor) else torch.tensor([epsilons_]).to(device_)\n",
    "    are_adv = torch.zeros_like(epsilons_)\n",
    "    are_adv = are_adv.to(device_)\n",
    "    for composites, labels, *_ in dataloader_:\n",
    "        epoch_t = time.time()\n",
    "        k = composites.size(0)\n",
    "        n_samples += k\n",
    "        composites, labels = composites.to(device_), labels.to(device_)\n",
    "        composites, labels = composites[:, 0], labels[:, 0]\n",
    "        p_acc = foolbox.utils.accuracy(fmodel, composites, labels)\n",
    "        pre_acc += (p_acc * k)\n",
    "        print(f\"Pre-accuracy: {p_acc:.2f}\")\n",
    "        raw, clipped, is_adv = attack(fmodel, composites, labels, epsilons=epsilons_)\n",
    "        print(f\"Adverserial robustness: {(1.0 - 1.0 * is_adv).sum()/k:.2f}\")\n",
    "        for i, eps in enumerate(epsilons_):\n",
    "            are_adv[i] += (1.0 - 1.0 * is_adv).sum()\n",
    "        print(f\"Batch time: {time.time() - epoch_t:.1f} sec.\")\n",
    "        if n_samples > 1000:\n",
    "            break\n",
    "    return pre_acc/n_samples, are_adv/n_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_robustness(model, tasks[\"Recognition\"][\"dataloaders\"][2], DeVice, \"Linf\", 0.001, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
