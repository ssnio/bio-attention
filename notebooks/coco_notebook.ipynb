{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # header\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imports\n",
    "import torch\n",
    "import os\n",
    "from pprint import pformat\n",
    "from src.composer import COCOTokens, COCOAnimals, BG20k\n",
    "from src.composer import PerceptualGrouping_COCO, Recognition_COCO, Search_COCO, SearchGrid_COCO\n",
    "from src.conductor import AttentionTrain\n",
    "from src.model import AttentionModel\n",
    "from src.utils import plot_all\n",
    "from src.utils import build_loaders, get_n_parameters\n",
    "from prelude import get_device, startup_folders, load_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/saeedida/GitProjects/bio-attention/pretrained/coco/1728903725 was created!\n"
     ]
    }
   ],
   "source": [
    "start_folder = r\"/Users/saeedida/GitProjects/bio-attention/pretrained/coco\"\n",
    "results_folder, logger = startup_folders(start_folder, name=f\"exp_coco\")\n",
    "data_path = r\"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to mps\n",
      "model_params: {'in_dims': [3, 256, 256], 'n_classes': 10, 'out_dim': 20, 'normalize': True, 'softness': [0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0], 'channels': [3, 32, 32, 64, 64, 128, 128, 256, 256], 'residuals': False, 'kernels': [7, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'strides': 1, 'paddings': 'same', 'conv_bias': True, 'conv_norms': [None, 'layer', 'layer', 'layer', 'layer', 'layer', 'layer', 'layer'], 'conv_dropouts': 0.0, 'conv_funs': GELU(approximate='none'), 'deconv_funs': GELU(approximate='none'), 'deconv_norms': [None, 'layer', 'layer', 'layer', 'layer', 'layer', 'layer', 'layer'], 'pools': 2, 'rnn_dims': [256], 'rnn_bias': True, 'rnn_dropouts': 0.0, 'rnn_funs': GELU(approximate='none'), 'n_tasks': 3, 'task_layers': 1, 'task_weight': True, 'task_bias': True, 'task_funs': Tanh(), 'rnn_to_fc': False, 'trans_fun': Identity(), 'affine': False}\n",
      "tasks: {'Recognition': {'composer': 'Recognition_COCO', 'key': 0, 'params': {'n_iter': 3, 'stride': 64, 'blank': False, 'static': False, 'noise': 0.25}, 'datasets': ['Recognition_COCO', 'Recognition_COCO', 'Recognition_COCO'], 'dataloaders': [None, None, None], 'loss_w': [0.1, 0.0, 0.5], 'loss_s': '(slice(1, None, None), None)', 'aux_params': None, 'class_weights': 'tensor([0.1345, 0.0650, 0.0688, 0.0736, 0.0990, 0.0896, 0.0752, 0.2503, 0.0761,\\n        0.0679])', 'has_prompt': False, 'random': None}, 'PerceptualGrouping': {'composer': 'PerceptualGrouping_COCO', 'key': 1, 'params': {'fix_attend': [2, 3], 'noise': 0.25}, 'datasets': ['PerceptualGrouping_COCO', 'PerceptualGrouping_COCO', 'PerceptualGrouping_COCO'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 1.0, 0.1], 'loss_s': '(None, slice(1, None, None))', 'aux_params': None, 'class_weights': 'tensor([0.1345, 0.0650, 0.0688, 0.0736, 0.0990, 0.0896, 0.0752, 0.2503, 0.0761,\\n        0.0679])', 'has_prompt': False, 'random': None}, 'Search': {'composer': 'Search_COCO', 'key': 2, 'params': {'n_iter': 3, 'noise': 0.25}, 'datasets': ['Search_COCO', 'Search_COCO', 'Search_COCO'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 1.0, 0.0], 'loss_s': '(None, slice(1, None, None))', 'aux_params': None, 'has_prompt': True, 'random': None}, 'SearchGrid': {'composer': 'SearchGrid_COCO', 'key': 2, 'params': {'n_iter': 3, 'noise': 0.25}, 'datasets': ['SearchGrid_COCO', 'SearchGrid_COCO', 'SearchGrid_COCO'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 1.0, 0.0], 'loss_s': '(None, slice(1, None, None))', 'aux_params': None, 'has_prompt': True, 'random': None}}\n",
      "train_params: {'n_epochs': 42, 'batch_size': 128, 'lr': 0.0005, 'l2': 1e-05, 'exase': 'default', 'dir': './results', 'milestones': [24, 32], 'gamma': 0.2, 'max_grad_norm': 10.0}\n"
     ]
    }
   ],
   "source": [
    "model_params = load_dicts(start_folder, \"model_params\")\n",
    "tasks = load_dicts(start_folder, \"tasks\")\n",
    "train_params = load_dicts(start_folder, \"train_params\")\n",
    "DeVice, num_workers, pin_memory = get_device()\n",
    "print(f\"model_params: {model_params}\")\n",
    "print(f\"tasks: {tasks}\")\n",
    "print(f\"train_params: {train_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks['Recognition'][\"composer\"] = Recognition_COCO\n",
    "tasks['PerceptualGrouping'][\"composer\"] = PerceptualGrouping_COCO\n",
    "tasks['Search'][\"composer\"] = Search_COCO\n",
    "tasks['SearchGrid'][\"composer\"] = SearchGrid_COCO\n",
    "\n",
    "tasks['Recognition'][\"datasets\"] = []\n",
    "tasks['PerceptualGrouping'][\"datasets\"] = []\n",
    "tasks['Search'][\"datasets\"] = []\n",
    "tasks['SearchGrid'][\"datasets\"] = []\n",
    "\n",
    "tasks['Recognition'][\"dataloaders\"] = []\n",
    "tasks['PerceptualGrouping'][\"dataloaders\"] = []\n",
    "tasks['Search'][\"dataloaders\"] = []\n",
    "tasks['SearchGrid'][\"dataloaders\"] = []\n",
    "\n",
    "tasks['Recognition'][\"loss_s\"] = (slice(0, None, None), slice(0, None, None))\n",
    "tasks['PerceptualGrouping'][\"loss_s\"] = (slice(1, None, None), slice(1, None, None))\n",
    "tasks['Search'][\"loss_s\"] = (slice(1, None, None), slice(1, None, None))\n",
    "tasks['SearchGrid'][\"loss_s\"] = (slice(1, None, None), slice(1, None, None))\n",
    "\n",
    "tasks['Recognition'][\"loss_s\"] = ((-1, ), (-1, ))\n",
    "tasks['PerceptualGrouping'][\"loss_s\"] = ((-1, ), (-1, ))\n",
    "tasks['Search'][\"loss_s\"] = ((-1, ), (-1, ))\n",
    "tasks['SearchGrid'][\"loss_s\"] = ((-1, ), (-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.49s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.56s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=11.77s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=15.53s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Device set to mps\n"
     ]
    }
   ],
   "source": [
    "# datasets and dataloaders\n",
    "coco_tokens = COCOTokens(directory=data_path, animals=True, split=0.9)\n",
    "train_tks, valid_tks, test_tks = coco_tokens.get_tokens()\n",
    "train_coco = COCOAnimals(in_dims=model_params[\"in_dims\"], directory=data_path, kind=0, tokens=train_tks)\n",
    "valid_coco = COCOAnimals(in_dims=model_params[\"in_dims\"], directory=data_path, kind=1, tokens=valid_tks)\n",
    "test_coco = COCOAnimals(in_dims=model_params[\"in_dims\"], directory=data_path, kind=2, tokens=test_tks)\n",
    "train_bg = BG20k(root=data_path, kind=\"train\")\n",
    "test_bg = valid_bg = BG20k(root=data_path, kind=\"test\")\n",
    "DeVice, num_workers, pin_memory = get_device()\n",
    "for o in tasks:\n",
    "    if tasks[o][\"composer\"] in (Recognition_COCO , SearchGrid_COCO):\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](train_coco, **tasks[o][\"params\"], bg_dataset=train_bg))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](valid_coco, **tasks[o][\"params\"], bg_dataset=valid_bg))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](test_coco, **tasks[o][\"params\"], bg_dataset=test_bg))\n",
    "    else:\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](train_coco, **tasks[o][\"params\"]))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](valid_coco, **tasks[o][\"params\"]))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](test_coco, **tasks[o][\"params\"]))\n",
    "    tasks[o][\"datasets\"][1].build_valid_test()\n",
    "    tasks[o][\"datasets\"][2].build_valid_test()\n",
    "    tasks[o][\"dataloaders\"] = build_loaders(tasks[o][\"datasets\"], batch_size=train_params[\"batch_size\"], num_workers=num_workers, pin_memory=pin_memory, shuffle=False)\n",
    "assert model_params[\"n_classes\"] == train_coco.n_classes, f\"Number of n_classes {model_params['n_classes']} and n_classes {train_coco.n_classes} must be equal!\"\n",
    "tasks[\"PerceptualGrouping\"][\"class_weights\"] = train_coco.class_weights if hasattr(train_coco, \"class_weights\") else None\n",
    "tasks[\"Recognition\"][\"class_weights\"] = train_coco.class_weights if hasattr(train_coco, \"class_weights\") else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AttentionModel(\n",
      "  (task_funs): Tanh()\n",
      "  (trans_fun): Identity()\n",
      "  (conv_blocks): ModuleList(\n",
      "    (0): ConvBlock(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
      "      (norm): Identity()\n",
      "      (fun): GELU(approximate='none')\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (norm): GroupNorm(1, 32, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (norm): GroupNorm(1, 64, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (3): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (norm): GroupNorm(1, 64, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (4): ConvBlock(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (norm): GroupNorm(1, 128, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (5): ConvBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (norm): GroupNorm(1, 128, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (6): ConvBlock(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (norm): GroupNorm(1, 256, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (7): ConvBlock(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (norm): GroupNorm(1, 256, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "  )\n",
      "  (deconv_blocks): ModuleList(\n",
      "    (0): DeConvBlock(\n",
      "      (upsample): Upsample(size=(2, 2), mode='nearest')\n",
      "      (deconv): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(1, 256, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "    )\n",
      "    (1): DeConvBlock(\n",
      "      (upsample): Upsample(size=(4, 4), mode='nearest')\n",
      "      (deconv): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(1, 128, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "    )\n",
      "    (2): DeConvBlock(\n",
      "      (upsample): Upsample(size=(8, 8), mode='nearest')\n",
      "      (deconv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(1, 128, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "    )\n",
      "    (3): DeConvBlock(\n",
      "      (upsample): Upsample(size=(16, 16), mode='nearest')\n",
      "      (deconv): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(1, 64, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "    )\n",
      "    (4): DeConvBlock(\n",
      "      (upsample): Upsample(size=(32, 32), mode='nearest')\n",
      "      (deconv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(1, 64, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "    )\n",
      "    (5): DeConvBlock(\n",
      "      (upsample): Upsample(size=(64, 64), mode='nearest')\n",
      "      (deconv): ConvTranspose2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(1, 32, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "    )\n",
      "    (6): DeConvBlock(\n",
      "      (upsample): Upsample(size=(128, 128), mode='nearest')\n",
      "      (deconv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(1, 32, eps=1e-05, affine=False)\n",
      "      (fun): GELU(approximate='none')\n",
      "    )\n",
      "    (7): DeConvBlock(\n",
      "      (upsample): Upsample(size=[256, 256], mode='nearest')\n",
      "      (deconv): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): Identity()\n",
      "      (fun): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (embed_blocks_a): ModuleList(\n",
      "    (0): Embedding(3, 512)\n",
      "  )\n",
      "  (embed_blocks_b): ModuleList(\n",
      "    (0): Embedding(3, 512)\n",
      "  )\n",
      "  (bridges): ModuleList()\n",
      "  (conv_frnn): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (2): Identity()\n",
      "  )\n",
      "  (fc_out): Linear(in_features=256, out_features=20, bias=True)\n",
      "  (fc_in): Linear(in_features=23, out_features=256, bias=True)\n",
      "  (brnn_deconv): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): Identity()\n",
      "    (2): Unflatten(dim=1, unflattened_size=(256, 1, 1))\n",
      "  )\n",
      ")\n",
      "Model has 3,664,181 parameters!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model and optimizer...\n",
    "model = AttentionModel(**model_params)\n",
    "logger.info(model)\n",
    "logger.info(f\"Model has {get_n_parameters(model):,} parameters!\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_params[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=train_params[\"milestones\"], gamma=train_params[\"gamma\"])\n",
    "model_trainer = AttentionTrain(model, optimizer, scheduler, tasks, logger, results_folder)\n",
    "\n",
    "# load model\n",
    "model_dir = os.path.join(start_folder, \"model\" + \".pth\")\n",
    "assert os.path.exists(model_dir), \"Could not find the model.pth in the given dir!\"\n",
    "model.load_state_dict(torch.load(model_dir, map_location=DeVice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "plot_all(10, model, tasks, results_folder, \"_test\", DeVice, logger, False, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing...\n",
      "  Task Recognition:\n",
      "    CEi Loss: 0.055770    CEe Loss: 0.056129    Pix Err: 0.029281    Att Acc: 0.916078    Cls Acc: 1233/1558\n",
      "  Task PerceptualGrouping:\n",
      "    CEi Loss: 0.066535    CEe Loss: 0.065844    Pix Err: 0.028895    Att Acc: 0.858874    Cls Acc: 1179/1558\n",
      "  Task Search:\n",
      "    CEi Loss: 0.714598    CEe Loss: 0.676482    Pix Err: 0.035254    Att Acc: 0.872138    Cls Acc: 482/646\n",
      "  Task SearchGrid:\n",
      "    CEi Loss: 0.551441    CEe Loss: 0.535923    Pix Err: 0.023674    Att Acc: 0.880425    Cls Acc: 1282/1558\n"
     ]
    }
   ],
   "source": [
    "# evaluating...\n",
    "model_trainer.eval(DeVice, \"test\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
