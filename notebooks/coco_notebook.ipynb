{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # header\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imports\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "from pprint import pformat\n",
    "from collections import OrderedDict\n",
    "from src.composer import COCOTokens, COCOAnimals, BG20k\n",
    "from src.composer import PerceptualGrouping_COCO, Recognition_COCO, Search_COCO, SearchGrid_COCO\n",
    "from src.conductor import AttentionTrain\n",
    "from src.modelv2 import AttentionModel\n",
    "from src.utils import plot_all, plot_loss_all\n",
    "from src.utils import build_loaders, get_n_parameters\n",
    "from prelude import get_device, startup_folders, load_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pretrained/coco_v2/1769695544 was created!\n"
     ]
    }
   ],
   "source": [
    "start_folder = r\"../pretrained/coco_v2\"\n",
    "results_folder, logger = startup_folders(start_folder, name=f\"exp_coco\")\n",
    "data_path = r\"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to mps\n",
      "model_params: {'channels': [32, 64, 128, 256, 512], 'fun': GELU(approximate='none'), 'in_dims': [3, 256, 256], 'mid_dim': -1, 'n_classes': 10, 'n_tasks': 3, 'norm': 'layer', 'out_dim': 10, 'softness': 0.5, 'task_fun': Tanh(), 'bnpti': False, 'recurrent': False, 'concat': True, 'resnet': False}\n",
      "tasks: {'Recognition': {'composer': 'Recognition_COCO', 'key': 0, 'params': {'n_iter': 3, 'stride': 64, 'blank': False, 'static': False, 'noise': 0.25}, 'datasets': ['Recognition_COCO', 'Recognition_COCO', 'Recognition_COCO'], 'dataloaders': [None, None, None], 'loss_w': [0.25, 0.0, 0.5], 'loss_s': '(slice(1, None, None), None)', 'class_weights': 'tensor([0.1306, 0.0649, 0.0684, 0.0739, 0.0956, 0.0905, 0.0757, 0.2579, 0.0753,\\n        0.0672])', 'has_prompt': False}, 'PerceptualGrouping': {'composer': 'PerceptualGrouping_COCO', 'key': 1, 'params': {'fix_attend': [2, 2], 'noise': 0.25, 'natural': False}, 'datasets': ['PerceptualGrouping_COCO', 'PerceptualGrouping_COCO', 'PerceptualGrouping_COCO'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 10.0, 0.25], 'loss_s': [None, [0, 2, 3]], 'class_weights': 'tensor([0.1306, 0.0649, 0.0684, 0.0739, 0.0956, 0.0905, 0.0757, 0.2579, 0.0753,\\n        0.0672])', 'has_prompt': False}, 'Search': {'composer': 'Search_COCO', 'key': 2, 'params': {'n_iter': 3, 'noise': 0.25}, 'datasets': ['Search_COCO', 'Search_COCO', 'Search_COCO'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 10.0, 0.0], 'loss_s': '(None, slice(1, None, None))', 'has_prompt': True}, 'SearchGrid': {'composer': 'SearchGrid_COCO', 'key': 2, 'params': {'n_iter': 3, 'noise': 0.25}, 'datasets': ['SearchGrid_COCO', 'SearchGrid_COCO', 'SearchGrid_COCO'], 'dataloaders': [None, None, None], 'loss_w': [0.0, 10.0, 0.0], 'loss_s': '(None, slice(1, None, None))', 'has_prompt': True}}\n",
      "train_params: {'n_epochs': 48, 'batch_size': 64, 'lr': 0.0005, 'l2': 0.0001, 'exase': 'default', 'dir': './results', 'milestones': [32, 40], 'gamma': 0.2, 'max_grad_norm': 10.0, 'lr_min': 1e-05, 'scheduler': 'OneCycleLR', 'optimizer': 'Adam', 'total_steps': 94864, 'pct_start': 0.25}\n"
     ]
    }
   ],
   "source": [
    "model_params = load_dicts(start_folder, \"model_params\")\n",
    "tasks = load_dicts(start_folder, \"tasks\")\n",
    "train_params = load_dicts(start_folder, \"train_params\")\n",
    "DeVice, num_workers, pin_memory = get_device()\n",
    "print(f\"model_params: {model_params}\")\n",
    "print(f\"tasks: {tasks}\")\n",
    "print(f\"train_params: {train_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks['Recognition'][\"composer\"] = Recognition_COCO\n",
    "tasks['PerceptualGrouping'][\"composer\"] = PerceptualGrouping_COCO\n",
    "tasks['Search'][\"composer\"] = Search_COCO\n",
    "tasks['SearchGrid'][\"composer\"] = SearchGrid_COCO\n",
    "\n",
    "tasks['Recognition'][\"datasets\"] = []\n",
    "tasks['PerceptualGrouping'][\"datasets\"] = []\n",
    "tasks['Search'][\"datasets\"] = []\n",
    "tasks['SearchGrid'][\"datasets\"] = []\n",
    "\n",
    "tasks['Recognition'][\"dataloaders\"] = []\n",
    "tasks['PerceptualGrouping'][\"dataloaders\"] = []\n",
    "tasks['Search'][\"dataloaders\"] = []\n",
    "tasks['SearchGrid'][\"dataloaders\"] = []\n",
    "\n",
    "tasks['Recognition'][\"loss_s\"] = (slice(0, None, None), slice(0, None, None))\n",
    "tasks['PerceptualGrouping'][\"loss_s\"] = (slice(1, None, None), slice(1, None, None))\n",
    "tasks['Search'][\"loss_s\"] = (slice(1, None, None), slice(1, None, None))\n",
    "tasks['SearchGrid'][\"loss_s\"] = (slice(1, None, None), slice(1, None, None))\n",
    "\n",
    "tasks['Recognition'][\"loss_s\"] = ((-1, ), (-1, ))\n",
    "tasks['PerceptualGrouping'][\"loss_s\"] = ((-1, ), (-1, ))\n",
    "tasks['Search'][\"loss_s\"] = ((-1, ), (-1, ))\n",
    "tasks['SearchGrid'][\"loss_s\"] = ((-1, ), (-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.95s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.89s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.22s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Device set to mps\n"
     ]
    }
   ],
   "source": [
    "# datasets and dataloaders\n",
    "coco_tokens = COCOTokens(directory=data_path, animals=True, split=0.9)\n",
    "train_tks, valid_tks, test_tks = coco_tokens.get_tokens()\n",
    "train_coco = COCOAnimals(in_dims=model_params[\"in_dims\"], directory=data_path, kind=0, tokens=train_tks)\n",
    "valid_coco = COCOAnimals(in_dims=model_params[\"in_dims\"], directory=data_path, kind=1, tokens=valid_tks)\n",
    "test_coco = COCOAnimals(in_dims=model_params[\"in_dims\"], directory=data_path, kind=2, tokens=test_tks)\n",
    "train_bg = BG20k(root=data_path, kind=\"train\")\n",
    "test_bg = valid_bg = BG20k(root=data_path, kind=\"test\")\n",
    "DeVice, num_workers, pin_memory = get_device()\n",
    "for o in tasks:\n",
    "    if tasks[o][\"composer\"] in (Recognition_COCO , SearchGrid_COCO):\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](train_coco, **tasks[o][\"params\"], bg_dataset=train_bg))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](valid_coco, **tasks[o][\"params\"], bg_dataset=valid_bg))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](test_coco, **tasks[o][\"params\"], bg_dataset=test_bg))\n",
    "    else:\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](train_coco, **tasks[o][\"params\"]))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](valid_coco, **tasks[o][\"params\"]))\n",
    "        tasks[o][\"datasets\"].append(tasks[o][\"composer\"](test_coco, **tasks[o][\"params\"]))\n",
    "    tasks[o][\"datasets\"][1].build_valid_test()\n",
    "    tasks[o][\"datasets\"][2].build_valid_test()\n",
    "    tasks[o][\"dataloaders\"] = build_loaders(tasks[o][\"datasets\"], batch_size=train_params[\"batch_size\"], num_workers=num_workers, pin_memory=pin_memory, shuffle=False)\n",
    "assert model_params[\"n_classes\"] == train_coco.n_classes, f\"Number of n_classes {model_params['n_classes']} and n_classes {train_coco.n_classes} must be equal!\"\n",
    "tasks[\"PerceptualGrouping\"][\"class_weights\"] = train_coco.class_weights if hasattr(train_coco, \"class_weights\") else None\n",
    "tasks[\"Recognition\"][\"class_weights\"] = train_coco.class_weights if hasattr(train_coco, \"class_weights\") else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model and optimizer...\n",
    "model = AttentionModel(**model_params)\n",
    "model_trainer = AttentionTrain(model, None, None, tasks, logger, results_folder)\n",
    "model_dir = os.path.join(start_folder, \"model\" + \".pth\")\n",
    "assert os.path.exists(model_dir), \"Could not find the model.pth in the given dir!\"\n",
    "model.load_state_dict(torch.load(model_dir, map_location=DeVice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "plot_all(10, model, tasks, results_folder, \"_test\", DeVice, logger, False, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing...\n",
      "  Task Recognition:\n",
      "    CEi Loss: 0.044    CEe Loss: 0.044    Pix Err: 0.027    Att Acc: 0.958    Cls Acc: 1332/1558\n",
      "  Task PerceptualGrouping:\n",
      "    CEi Loss: 0.045    CEe Loss: 0.044    Pix Err: 0.020    Att Acc: 0.907    Cls Acc: 1325/1558\n",
      "  Task Search:\n",
      "    CEi Loss: 0.469    CEe Loss: 0.469    Pix Err: 0.024    Att Acc: 0.913    Cls Acc: 543/646\n",
      "  Task SearchGrid:\n",
      "    CEi Loss: 0.756    CEe Loss: 0.751    Pix Err: 0.011    Att Acc: 0.943    Cls Acc: 1183/1558\n",
      "validating...\n",
      "  Task Recognition:\n",
      "    CEi Loss: 0.019    CEe Loss: 0.019    Pix Err: 0.026    Att Acc: 0.960    Cls Acc: 3112/3375\n",
      "  Task PerceptualGrouping:\n",
      "    CEi Loss: 0.024    CEe Loss: 0.022    Pix Err: 0.015    Att Acc: 0.930    Cls Acc: 3054/3375\n",
      "  Task Search:\n",
      "    CEi Loss: 0.284    CEe Loss: 0.278    Pix Err: 0.014    Att Acc: 0.948    Cls Acc: 1397/1545\n",
      "  Task SearchGrid:\n",
      "    CEi Loss: 0.519    CEe Loss: 0.507    Pix Err: 0.007    Att Acc: 0.962    Cls Acc: 2840/3375\n"
     ]
    }
   ],
   "source": [
    "# evaluating...\n",
    "model_trainer.eval(DeVice, \"test\", False)\n",
    "model_trainer.eval(DeVice, \"valid\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
